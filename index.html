<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Octree Guided Unoriented Surface Reconstruction</title>
    <meta name="author" 
          content="Chamin Hewa Koneputugodage, Yizhak Ben-Shabat (Itzik) and Stephen Gould">
    <meta name="description"
          content="Octree Guided Unoriented Surface Reconstruction">
    <meta name="keywords" content="OG-INR, Surface Reconstruction, Octree, Point Clouds, Unoriented Point Clouds">

    <link rel="stylesheet" href="./css/index.css">
</head>
<body>

<section class="hero">
    <div class="default-container">
        <div class="title-block">
            <h1 class="title">Octree Guided Unoriented Surface Reconstruction</h1>
            <h2 class="venue">CVPR 2023</h2>
        </div>
        <div class="author-section">
            <span class="author">
                <a href="https://www.linkedin.com/in/chamin-hewa-koneputugodage-b3ba17148/">
                    <img class="image" src="./images/chamin.jpg" alt="Chamin Hewa Koneputugodage">
                </a> <br/>
                <a href="https://www.linkedin.com/in/chamin-hewa-koneputugodage-b3ba17148/">Chamin Hewa 
                    <br> Koneputugodage</a><sup>1</sup>
            </span>
            <span class="author">
                <a href="https://www.itzikbs.com/">
                    <img class="image" src="./images/itzik.jpg" alt="Yizhak Ben-Shabat (Itzik)">
                </a> <br/>
                <a href="https://www.itzikbs.com/">Yizhak Ben-Shabat <br> (Itzik)*</a><sup>1,2</sup>
            </span>
            <span class="author">
                <a href="https://cecs.anu.edu.au/people/stephen-gould/">
                    <img class="image" src="./images/steve.jpg" alt="Stephen Gould">
                </a> <br/>
                <a href="https://cecs.anu.edu.au/people/stephen-gould/">Stephen Gould </a><sup>1</sup><br><a>&nbsp</a>
            </span>
        </div>

        <div class="affiliation">
            <sup>1</sup><a>The Australian National University</a>
            &emsp;
            <sup>2</sup><a>Technion</a>&emsp;
        </div>
        
        <div class="links">
            <span class="link-block">
                <a href="https://openreview.net/pdf?id=jSuYeWKw2Z" class="button-80">
                    <img class="link-icon" src="./images/pdf.svg" alt="Paper">
                    <span> Paper</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://drive.google.com/file/d/1CukGdzsENoeRDVJd5Ycsn1r34mylhoz4/view?usp=sharing" class="button-80">
                    <img class="link-icon" src="./images/pdf.svg" alt="Supplemental">
                    <span> Supplemental</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://drive.google.com/file/d/1_Y8xEfTe8DgMDITYgF7rhHHVJo86wFny/view?usp=sharing" class="button-80">
                    <img class="link-icon" src="./images/pdf.svg" alt="Poster">
                    <span> Poster</span>
                </a>
            </span>
            <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2106.10811" class="button-80">
                    <img class="link-icon" src="./images/arxiv.png" alt="arxiv">
                    <span> Arxiv</span>
                </a> -->
            </span>
            <!-- <span class="link-block">
                <a href="coming_soon.html" class="button-80">
                    <img class="link-icon" src="./images/jupyter.svg" alt="Jupter Notebook">
                    <span> Jupter Notebook</span>
                </a>
            </span> -->
            <span class="link-block">
                <!-- <a href="https://github.com/Chumbyte/DiGS" class="button-80"> -->
                <a class="button-80">
                    <img class="link-icon" src="./images/github.svg" alt="Code">
                    <span> Code Coming Soon</span>
                </a>
            </span>
            <span class="link-block">
                <a href="https://www.youtube.com/watch?v=Kh4Qohl2Zr8&ab_channel=anucvml" class="button-80">
                    <img class="link-icon" src="./images/youtube.svg" alt="Video">
                    <span> Video</span>
                </a>
            </span>
            <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=w2xC2JluMlk&ab_channel=TalkingPapersPodcast" class="button-80">
                    <img class="link-icon" src="./images/youtube.svg" alt="Video">
                    <span> Podcast</span>
                </a>
            </span> -->
        </div>

    </div>
</section>

<!-- <section class="teaser-results">
    <div class="default-container">
        <div class="srb-comp-row">
            <div class="srb-vid-column" style="overflow: hidden;">
                <video class="srb-video"  controls autoplay muted loop>
                    <source src="./videos/anchor-comp.mp4" type="video/mp4">
                </video>
            </div>
            <div class="srb-vid-column" style="overflow: hidden;">
                <video class="srb-video"  controls autoplay muted loop>
                    <source src="./videos/lord-quas-comp.mp4" type="video/mp4">
                </video>
            </div>
            <div class="srb-vid-column" style="overflow: hidden;">
                <video class="srb-video"  controls autoplay muted loop>
                    <source src="./videos/dc-comp.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <p>
            Results on the Surface Reconstruction Benchmark. DiGS, <em>which does not use normals</em>, does as well as 
            methods that use normals (SIREN shown here) and much better than methods that do not (IGR wo n shown here).
        </p>
        <div class="scene-row" style="overflow: hidden;">
            <video class="scene-video"  controls autoplay muted loop>
                <source src="./videos/scene.mp4" type="video/mp4">
            </video>
        </div>
        <p>
            Results on the scene from SIREN's paper. To be able to fit complex scenes, normal supervision is essential for
            INR based methods. Here we demonstate that our method is able to still work well without normals, while SoTA 
            method SIREN has a lot of ghost geometry in the absence of normal supervision.
        </p>
    </div>
</section> -->



<section class="abstract-section">
    <div class="default-container">
        <div class="abstract">
            <h2 class="abstract-title">Abstract</h2>
            <p class="abstract-text">
                We address the problem of surface reconstruction from unoriented point clouds. Implicit neural representations (INRs) have become popular for this task, but when information relating to the inside versus outside of a shape is not available (such as shape occupancy, signed distances or surface normal orientation) optimization relies on heuristics and regularizers to recover the surface. These methods can be slow to converge and easily get stuck in local minima. 
                We propose a two-step approach, OG-INR, where we (1) construct a discrete octree and label what is inside and outside (2) optimize for a continuous and high-fidelity shape using an INR that is initially guided by the octree's labelling. To solve for our labelling, we propose an energy function over the discrete structure and provide an efficient move-making algorithm that explores many possible labellings. Furthermore we show that we can easily inject knowledge into the discrete octree, providing a simple way to influence the result from the continuous INR.
                We evaluate the effectiveness of our approach on two unoriented surface reconstruction datasets and show competitive performance compared to other unoriented, and some oriented, methods. Our results show that the exploration by the move-making algorithm avoids many of the bad local minima reached by purely gradient descent optimized methods.
            </p>
        </div>
    </div>
</section>

<section class="explanation-section">
    <div class="default-container">
        <div class="explanation">
            <div class="og-inr-expl">
                <img class="og-inr-expl-img" src="./images/Overview_transparent.png" alt="overview">
            </div>
            <h2 class="explanation-title">Octree Guided INRs (OG-INR)</h2>
            <p class="test">
                We address the problem of surface reconstruction from unoriented point clouds using implicit neural representations (INRs). In order to avoid bad local minima which gradient descent easily gets stuck in for this task, we propose a two step approach, OG-INR, where we 
                <ul>
                    <li>construct a discrete octree and label what is inside or outside</li>
                    <li>optimise an INR guided by the octreeâ€™s labelling.</li>
                  </ul>
                To solve for the labelling we propose an <strong>energy function</strong> and an <strong>efficient move making algorithm</strong> that explores many possible labellings.
            </p>
            
            <!-- <h3>Energy Function</h3>
            <p>
                To label the octree, we propose an energy function that captures the surface reconstruction task. 
                The first term encodes a surface property, while the second term encodes a minimal surface constraint.
                
                The surface property term encourages every surface node to be close to an inside or outside node. In practice we only look at its direct neighbours, encourage a specific quota on the number of inside and outside neighbours, and count surface neighbours as a mixture of inside and outside.
                
                The minimal surface constraint encourages the surface area between nodes labelled as inside and nodes labelled as outside to be minimised.
                
            </p>
            
            <h3>Move Making Algorithm</h3>
            <p>
                This energy function is non-trivial to minimize. In particular it contains an n-ary term that is not concave, so we cannot use efficient methods for exact inference.

                We employ a move making algorithm, with moves specialised to the problem (click)

                To make it efficient, we constrain the move set and use a coarse to fine approach
                1. We only allow labels to change from inside to outside
                2. We only change labels for nodes on the inside-outside border
                3. We Iteratively grow potential moves
                4. Finally, we Apply moves at multiple octree depths before reaching the final depth

            </p> -->
        </div>
    </div>
</section>


<section class="teaser-results">
    <div class="default-container">
        <div class="srb-comp-row">
            <img class="og-inr-expl-img" src="./images/ShapeNet_comp.png" alt="ShapeNet">
        </div>
        <p>
            Results on Shapenet
        </p>
        <div class="srb-comp-row">
            <img class="og-inr-expl-img" src="./images/SRB_comp.png" alt="SRB">
        </div>
        <p>
            Results on SRB
        </p>
    </div>
</section>

<section class="main-video-section">
    <div class="default-container">
        <div class="main-video">
            <h2 class="main-video-title">Video</h2>
            <div class="main-video-div">
                <!-- <iframe src="https://www.youtube.com/embed/TcbErocpnak?rel=0&amp;showinfo=0" -->
                <!-- <iframe src="https://www.youtube.com/embed/bQWpRyM9wYM?rel=0&amp;showinfo=0"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
                <iframe width="560" height="315" src="https://www.youtube.com/embed/Kh4Qohl2Zr8" title="YouTube video player" frameborder="0" 
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
            <!-- <p style="text-align: justify"><b>Coming Soon!</b></p> -->
        </div>
    </div>

<section class="thanks-section">
    <div class="default-container">
        <div class="thanks">
            <h2 class="thanks-title">Acknowledgements</h2>
            <p class="thanks-text">
                This work has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 893465. S. Gould is a recipient of an ARC Future Fellowship (proj. no. LP200100421) funded by the Australian Government.

            </p>
        </div>
    </div>
</section>


<section class="reference-section">
    <div class="default-container">
        <div class="ref">
            <h2 class="ref-title">BibTeX</h2>
            <div class="bibtex">
<pre><code>@inproceedings{koneputugodage2023octree,
        title={Octree Guided Unoriented Surface Reconstruction},
        author={Koneputugodage, Chamin Hewa and Ben-Shabat, Yizhak and Gould, Stephen},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        pages={16717--16726},
        year={2023}
      }
  }</code></pre>
            </div>
        </div>
    </div>
</section>

</body>
</html>

